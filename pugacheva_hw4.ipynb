{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Алгоритмы интеллектуальной обработки больших объемов данных\n",
    "## Домашнее задание №4 - Градиентный бустинг\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "**Общая информация**\n",
    "\n",
    "**Срок сдачи:** 13 июня 2022, 08:30   \n",
    "**Штраф за опоздание:** -2 балла после 08:30 13 июня, -4 балла после 08:30 20 июня, -6 баллов после 08:30 24 июня, -8 баллов после 08:30 31 мая.\n",
    "\n",
    "При отправлении ДЗ указывайте фамилию в названии файла Присылать ДЗ необходимо в виде ссылки на свой github репозиторий на почту ml1.sphere@mail.ru с указанием темы в следующем формате:\n",
    "[ML0422, Задание 4] Фамилия Имя. \n",
    "\n",
    "\n",
    "Используйте данный Ipython Notebook при оформлении домашнего задания."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Считаем производные для функций потерь (1 балл)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Мы будем реализовать градиентный бустинг для 3 функций потерь:\n",
    "\n",
    "1) MSE  $L(a(x_i), y_i) = (y_i - a(x_i)) ^ 2$\n",
    "\n",
    "2) Экспоненциальная  $L(a(x_i), y_i) = exp( -a(x_i) y_i), y_i \\in \\{-1, 1\\}$\n",
    "\n",
    "3) Логистическая  $L(a(x_i), y_i) = \\log (1 + exp( -a(x_i) y_i)), y_i \\in \\{-1, 1\\}$\n",
    "\n",
    "где $a(x_i)$ предсказание бустинга на итом объекте. \n",
    "\n",
    "Для каждой функции потерь напишите таргет, на который будет настраиваться каждое дерево в бустинге. "
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Вместо $\\xi$ надо подставлять $a_{k-1} (x_i)$, вместо $\\eta$ надо подставлять $y_i$.\n",
    "1) MSE\n",
    "\n",
    "$L(\\xi, \\eta) = (\\xi - \\eta)^2$, \n",
    "\n",
    "$-\\dfrac{\\partial L}{\\partial \\xi} = -2(\\xi-\\eta)$ \n",
    "\n",
    "\n",
    "2) $L(\\xi, \\eta) = \\exp(-\\xi\\eta)$,\n",
    "\n",
    "$- \\dfrac{\\partial L}{\\partial \\xi} = \\eta \\exp(-\\xi\\eta)$\n",
    "\n",
    "\n",
    "3) $L(\\xi, \\eta) = log\\big(1+\\exp(-\\xi\\eta)\\big)$,\n",
    "\n",
    "$- \\dfrac{\\partial L}{\\partial \\xi} = \\dfrac{\\eta \\exp(-\\xi\\eta)}{1 + \\exp(-\\xi\\eta)}$"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "##  Реализуем градиентный бустинг (3 балла)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Реализуйте класс градиентного бустинга для классификации. Ваша реализация бустинга должна работать по точности не более чем на 5 процентов хуже чем GradientBoostingClassifier из sklearn. \n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Детали реализации:\n",
    "\n",
    "-- должно поддерживаться 3 функции потерь\n",
    "\n",
    "-- сами базовые алгоритмы(деревья, линейные модели и тп) реализовать не надо, просто возьмите готовые из sklearn\n",
    "\n",
    "-- в качестве функции потерь для построения одного дерева используйте MSE\n",
    "\n",
    "-- шаг в бустинге можно не подбирать, можно брать константный\n",
    "\n",
    "-- можно брать разные модели в качестве инициализации бустинга\n",
    "\n",
    "-- должны поддерживаться следующие параметры:\n",
    "\n",
    "а) число итераций\n",
    "б) размер шага\n",
    "в) процент случайных фичей при построении одного дерева\n",
    "д) процент случайных объектов при построении одного дерева\n",
    "е) параметры базового алгоритма (передавайте через **kwargs)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "import numpy as np\n",
    "\n",
    "from sklearn.datasets import load_wine\n",
    "from sklearn.ensemble import GradientBoostingClassifier\n",
    "\n",
    "from sklearn.metrics import accuracy_score\n",
    "from sklearn.model_selection import train_test_split\n",
    "from sklearn.tree import DecisionTreeRegressor\n",
    "\n",
    "import math\n",
    "\n",
    "from sklearn.model_selection import cross_val_score\n",
    "from sklearn.metrics import accuracy_score"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "class MyGradientBoostingClassifier:\n",
    "\n",
    "    @staticmethod\n",
    "    def log_loss_antigrad(xi, eta):\n",
    "        exp = math.e ** (-xi * eta)\n",
    "        return eta * exp / (1 + exp)\n",
    "    \n",
    "    @staticmethod\n",
    "    def exponential_antigrad(xi, eta):\n",
    "        exp = math.e ** (-xi * eta)\n",
    "        return eta * exp\n",
    "    \n",
    "    @staticmethod\n",
    "    def mse_antigrad(xi, eta):\n",
    "        return 2 * (eta - xi)\n",
    "    \n",
    "        \n",
    "    def __init__(self, loss='log_loss', learning_rate=0.1, n_estimators=500, colsample=1.0, subsample=1.0, *args, **kwargs):\n",
    "        \"\"\"\n",
    "        loss -- один из 3 лоссов:\n",
    "        learning_rate -- шаг бустинга\n",
    "        n_estimators -- число итераций\n",
    "        colsample -- процент рандомных признаков при обучнеии одного алгоритма\n",
    "        subsample -- процент рандомных объектов при обучнеии одного алгоритма\n",
    "        args, kwargs -- параметры  базовых моделей\n",
    "        \"\"\"\n",
    "        \n",
    "        self.loss_function_antigrad = MyGradientBoostingClassifier.log_loss_antigrad\n",
    "        \n",
    "        \"\"\"\n",
    "        if loss == 'log_loss':\n",
    "            self.loss_function_antigrad = MyGradientBoostingClassifier.log_loss_antigrad\n",
    "        if loss == 'exponential':\n",
    "            self.loss_function_antigrad = MyGradientBoostingClassifier.exponential_antigrad\n",
    "        if loss == 'mse':\n",
    "            self.loss_function_antigrad = MyGradientBoostingClassifier.mse_antigrad\n",
    "        \"\"\"\n",
    "        \n",
    "        \n",
    "        \n",
    "        self.learning_rate = learning_rate\n",
    "        self.n_estimators = n_estimators\n",
    "        self.colsample = colsample\n",
    "        self.subsample = subsample\n",
    "        self.args = args\n",
    "        self.kwargs = kwargs\n",
    "        \n",
    "        self.models = []\n",
    "        pass\n",
    "    \n",
    "    \n",
    "    def fit(self, X, y, base_model=DecisionTreeRegressor, init_model=None):\n",
    "        \"\"\"\n",
    "        X -- объекты для обучения:\n",
    "        y -- таргеты для обучения\n",
    "        base_model -- класс базовых моделей, например sklearn.tree.DecisionTreeRegressor\n",
    "        init_model -- класс для первой модели, если None то берем константу (только для посл задания)\n",
    "        \"\"\"\n",
    "        \n",
    "        antigradient = y\n",
    "\n",
    "        xi = 0\n",
    "        \n",
    "        for step in range(self.n_estimators):   \n",
    "            # выбираем subsample\n",
    "            n = int(y.size * self.subsample) \n",
    "            index = sorted(np.random.choice(X.shape[0], n, replace=False))\n",
    "            rnd_X = X[index]\n",
    "            rnd_antigradient = antigradient[index]\n",
    "            \n",
    "            # выбираем colsample\n",
    "            m = int(X.shape[1] * self.colsample)\n",
    "            cols = sorted(np.random.choice(X.shape[1], m, replace=False))\n",
    "            subcols_rnd_X = rnd_X[:, cols]\n",
    "                    \n",
    "            \n",
    "            # обучаем base_model предсказывать антиградиент на subcols_rnd_X\n",
    "            f_k = base_model(*self.args, **self.kwargs)\n",
    "            f_k.fit(subcols_rnd_X, rnd_antigradient)\n",
    "            \n",
    "            subcols_X = X[:, cols] # не забываем фитить тоже на subcols\n",
    "            if step > 0:\n",
    "                xi += self.learning_rate * f_k.predict(subcols_X)\n",
    "            else:\n",
    "                xi += f_k.predict(subcols_X)\n",
    "                \n",
    "        \n",
    "            self.models.append(f_k)\n",
    "            \n",
    "            antigradient = self.loss_function_antigrad(xi, y)\n",
    "\n",
    "        \n",
    "    \n",
    "    def predict(self, X):\n",
    "        xi = 0\n",
    "        for i in range(len(self.models)):\n",
    "            if i==0:\n",
    "                xi += self.models[i].predict(X) \n",
    "            else:\n",
    "                xi += self.learning_rate * self.models[i].predict(X)        \n",
    "        return np.array(np.sign(xi), dtype='int')\n",
    "\n",
    "    \n",
    "    \n",
    "    def score(self, X, y_true):\n",
    "        return accuracy_score(self.predict(X), y_true)\n",
    "    \n",
    "    def get_params(self, deep=False):\n",
    "        return {\n",
    "            'loss':self.loss_function_antigrad,\n",
    "            'learning_rate': self.learning_rate, \n",
    "            'n_estimators': self.n_estimators, \n",
    "            'colsample': self.colsample, \n",
    "            'subsample': self.subsample\n",
    "        }"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "my_clf = MyGradientBoostingClassifier()\n",
    "clf = GradientBoostingClassifier()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": [
    "wine = load_wine()\n",
    "X_train, X_test, y_train, y_test = train_test_split(wine.data, wine.target, test_size=0.1, stratify=wine.target)\n",
    "\n",
    "y_train = (y_train > 0).astype(int)\n",
    "\n",
    "y_test = (y_test > 0).astype(int)\n",
    "\n",
    "# у меня бинарный классификатор\n",
    "# а классов 3\n",
    "# не знаю, что подразумевалось - скомбинировать два (или три) бинарных классификатора\n",
    "# или модифицировать алгоритм из лекции так, чтобы он работал на трех классах\n",
    "# поэтому переделала данные на имеющие два класса"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1.0\n",
      "1.0\n"
     ]
    }
   ],
   "source": [
    "my_clf.fit(X_train, y_train)\n",
    "clf.fit(X_train, y_train)\n",
    "print(accuracy_score(y_pred=clf.predict(X_test), y_true=y_test))\n",
    "print(accuracy_score(y_pred=my_clf.predict(X_test), y_true=y_test))"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Подбираем параметры (2 балла)\n",
    "\n",
    "Давайте попробуем применить Ваш бустинг для предсказаний цены домов в Калифорнии. Чтобы можно было попробовтаь разные функции потерь, переведем по порогу таргет в 2 класса: дорогие и дешевые дома."
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "В задании нужно\n",
    "\n",
    "1) Построить график точности в зависимости от числа итераций на валидации.\n",
    "\n",
    "2) Подобрать оптимальные параметры Вашего бустинга на валидации. \n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "from sklearn.datasets import fetch_california_housing\n",
    "X, y = fetch_california_housing(return_X_y=True)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "(20640, 8) (20640,)\n",
      "8709\n"
     ]
    }
   ],
   "source": [
    "# Превращаем регрессию в классификацию\n",
    "y = (y > 2.0).astype(int)\n",
    "print(X.shape, y.shape)\n",
    "\n",
    "print(sum(y))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "  0%|                                                    | 0/4 [01:38<?, ?it/s]\n"
     ]
    },
    {
     "ename": "KeyboardInterrupt",
     "evalue": "",
     "output_type": "error",
     "traceback": [
      "\u001b[1;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m                         Traceback (most recent call last)",
      "\u001b[1;32m<ipython-input-8-46fa9f6f05d4>\u001b[0m in \u001b[0;36m<module>\u001b[1;34m\u001b[0m\n\u001b[0;32m      8\u001b[0m     \u001b[0mclf\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mMyGradientBoostingClassifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m      9\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 10\u001b[1;33m     cv_score = cross_val_score(\n\u001b[0m\u001b[0;32m     11\u001b[0m         \u001b[0mclf\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     12\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\documents\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_val_score\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, error_score)\u001b[0m\n\u001b[0;32m    507\u001b[0m     \u001b[0mscorer\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mcheck_scoring\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mscoring\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mscoring\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    508\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 509\u001b[1;33m     cv_results = cross_validate(\n\u001b[0m\u001b[0;32m    510\u001b[0m         \u001b[0mestimator\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    511\u001b[0m         \u001b[0mX\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\documents\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36mcross_validate\u001b[1;34m(estimator, X, y, groups, scoring, cv, n_jobs, verbose, fit_params, pre_dispatch, return_train_score, return_estimator, error_score)\u001b[0m\n\u001b[0;32m    265\u001b[0m     \u001b[1;31m# independent, and that it is pickle-able.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    266\u001b[0m     \u001b[0mparallel\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mParallel\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mn_jobs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mverbose\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mverbose\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mpre_dispatch\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mpre_dispatch\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 267\u001b[1;33m     results = parallel(\n\u001b[0m\u001b[0;32m    268\u001b[0m         delayed(_fit_and_score)(\n\u001b[0;32m    269\u001b[0m             \u001b[0mclone\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mestimator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\documents\\miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, iterable)\u001b[0m\n\u001b[0;32m   1041\u001b[0m             \u001b[1;31m# remaining jobs.\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1042\u001b[0m             \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1043\u001b[1;33m             \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mdispatch_one_batch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0miterator\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m   1044\u001b[0m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_iterating\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_original_iterator\u001b[0m \u001b[1;32mis\u001b[0m \u001b[1;32mnot\u001b[0m \u001b[1;32mNone\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1045\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\documents\\miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36mdispatch_one_batch\u001b[1;34m(self, iterator)\u001b[0m\n\u001b[0;32m    859\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mFalse\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    860\u001b[0m             \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 861\u001b[1;33m                 \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_dispatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mtasks\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    862\u001b[0m                 \u001b[1;32mreturn\u001b[0m \u001b[1;32mTrue\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    863\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\documents\\miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m_dispatch\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    777\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_lock\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    778\u001b[0m             \u001b[0mjob_idx\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mlen\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 779\u001b[1;33m             \u001b[0mjob\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mbatch\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mcb\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    780\u001b[0m             \u001b[1;31m# A job can complete so quickly than its callback is\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    781\u001b[0m             \u001b[1;31m# called before we get here, causing self._jobs to\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\documents\\miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36mapply_async\u001b[1;34m(self, func, callback)\u001b[0m\n\u001b[0;32m    206\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mapply_async\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mfunc\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m=\u001b[0m\u001b[1;32mNone\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    207\u001b[0m         \u001b[1;34m\"\"\"Schedule a func to be run\"\"\"\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 208\u001b[1;33m         \u001b[0mresult\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mImmediateResult\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mfunc\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    209\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mcallback\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    210\u001b[0m             \u001b[0mcallback\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mresult\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\documents\\miniconda3\\lib\\site-packages\\joblib\\_parallel_backends.py\u001b[0m in \u001b[0;36m__init__\u001b[1;34m(self, batch)\u001b[0m\n\u001b[0;32m    570\u001b[0m         \u001b[1;31m# Don't delay the application, to avoid keeping the input\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    571\u001b[0m         \u001b[1;31m# arguments in memory\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 572\u001b[1;33m         \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mresults\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbatch\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    573\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    574\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0mget\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\documents\\miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\documents\\miniconda3\\lib\\site-packages\\joblib\\parallel.py\u001b[0m in \u001b[0;36m<listcomp>\u001b[1;34m(.0)\u001b[0m\n\u001b[0;32m    260\u001b[0m         \u001b[1;31m# change the default number of processes to -1\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    261\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mparallel_backend\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_backend\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mn_jobs\u001b[0m\u001b[1;33m=\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0m_n_jobs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 262\u001b[1;33m             return [func(*args, **kwargs)\n\u001b[0m\u001b[0;32m    263\u001b[0m                     for func, args, kwargs in self.items]\n\u001b[0;32m    264\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\documents\\miniconda3\\lib\\site-packages\\sklearn\\utils\\fixes.py\u001b[0m in \u001b[0;36m__call__\u001b[1;34m(self, *args, **kwargs)\u001b[0m\n\u001b[0;32m    214\u001b[0m     \u001b[1;32mdef\u001b[0m \u001b[0m__call__\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    215\u001b[0m         \u001b[1;32mwith\u001b[0m \u001b[0mconfig_context\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mconfig\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 216\u001b[1;33m             \u001b[1;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfunction\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    217\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    218\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\documents\\miniconda3\\lib\\site-packages\\sklearn\\model_selection\\_validation.py\u001b[0m in \u001b[0;36m_fit_and_score\u001b[1;34m(estimator, X, y, scorer, train, test, verbose, parameters, fit_params, return_train_score, return_parameters, return_n_test_samples, return_times, return_estimator, split_progress, candidate_progress, error_score)\u001b[0m\n\u001b[0;32m    678\u001b[0m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    679\u001b[0m         \u001b[1;32melse\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 680\u001b[1;33m             \u001b[0mestimator\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mX_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my_train\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mfit_params\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    681\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    682\u001b[0m     \u001b[1;32mexcept\u001b[0m \u001b[0mException\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32m<ipython-input-2-77af84bc726d>\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, base_model, init_model)\u001b[0m\n\u001b[0;32m     77\u001b[0m             \u001b[1;31m# обучаем base_model предсказывать антиградиент на subcols_rnd_X\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     78\u001b[0m             \u001b[0mf_k\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mbase_model\u001b[0m\u001b[1;33m(\u001b[0m\u001b[1;33m*\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0margs\u001b[0m\u001b[1;33m,\u001b[0m \u001b[1;33m**\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m---> 79\u001b[1;33m             \u001b[0mf_k\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mfit\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0msubcols_rnd_X\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mrnd_antigradient\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m     80\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m     81\u001b[0m             \u001b[0msubcols_X\u001b[0m \u001b[1;33m=\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m[\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mcols\u001b[0m\u001b[1;33m]\u001b[0m \u001b[1;31m# не забываем фитить тоже на subcols\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\documents\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m   1313\u001b[0m         \"\"\"\n\u001b[0;32m   1314\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m-> 1315\u001b[1;33m         super().fit(\n\u001b[0m\u001b[0;32m   1316\u001b[0m             \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m   1317\u001b[0m             \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;32mc:\\users\\hp\\documents\\miniconda3\\lib\\site-packages\\sklearn\\tree\\_classes.py\u001b[0m in \u001b[0;36mfit\u001b[1;34m(self, X, y, sample_weight, check_input, X_idx_sorted)\u001b[0m\n\u001b[0;32m    418\u001b[0m             )\n\u001b[0;32m    419\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[1;32m--> 420\u001b[1;33m         \u001b[0mbuilder\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mbuild\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mtree_\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0mX\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0my\u001b[0m\u001b[1;33m,\u001b[0m \u001b[0msample_weight\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0m\u001b[0;32m    421\u001b[0m \u001b[1;33m\u001b[0m\u001b[0m\n\u001b[0;32m    422\u001b[0m         \u001b[1;32mif\u001b[0m \u001b[0mself\u001b[0m\u001b[1;33m.\u001b[0m\u001b[0mn_outputs_\u001b[0m \u001b[1;33m==\u001b[0m \u001b[1;36m1\u001b[0m \u001b[1;32mand\u001b[0m \u001b[0mis_classifier\u001b[0m\u001b[1;33m(\u001b[0m\u001b[0mself\u001b[0m\u001b[1;33m)\u001b[0m\u001b[1;33m:\u001b[0m\u001b[1;33m\u001b[0m\u001b[1;33m\u001b[0m\u001b[0m\n",
      "\u001b[1;31mKeyboardInterrupt\u001b[0m: "
     ]
    }
   ],
   "source": [
    "from tqdm import tqdm\n",
    "\n",
    "\n",
    "n_estimators_list = [1, 2, 4, 8] \n",
    "cv_scores = []\n",
    "\n",
    "for n_est in tqdm(n_estimators_list):\n",
    "    clf = MyGradientBoostingClassifier()\n",
    "    \n",
    "    cv_score = cross_val_score(\n",
    "        clf,\n",
    "        X,\n",
    "        y\n",
    "    ).mean()\n",
    "    cv_scores.append(cv_score)\n",
    "\n",
    "# оно почему-то навсегда остается на 0%\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 59,
   "metadata": {
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [
    {
     "data": {
      "image/png": "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\n",
      "text/plain": [
       "<Figure size 432x288 with 1 Axes>"
      ]
     },
     "metadata": {
      "needs_background": "light"
     },
     "output_type": "display_data"
    }
   ],
   "source": [
    "import matplotlib.pyplot as plt \n",
    "\n",
    "plt.plot(n_estimators_list, cv_scores, label='cv score')\n",
    "plt.xlabel('n_estimators')\n",
    "plt.ylabel('f1')\n",
    "plt.legend()\n",
    "plt.show()\n",
    "\n",
    "# этот график ничего не значит, я тестировала кусок кода на GradientBoostingClassifier"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## BooBag BagBoo (1 балл)\n",
    "\n"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуем объединить бустинг и бэгинг. Давайте\n",
    "\n",
    "1) в качестве базовой модели брать не дерево решений, а случайный лес (из sklearn)\n",
    "\n",
    "2) обучать N бустингов на бустрапированной выборке, а затем предикт усреднять"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Попробуйте обе этих стратегии на данных из прошлого задания. Получилось ли улучшить качество? Почему?"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Умная инициализация (1 балл)\n",
    "\n",
    "Попробуйте брать в качестве инициализации бустинга не константу, а какой-то алгоритм и уже от его предикта стартовать итерации бустинга. Попробуйте разные модели из sklearn: линейные модели, рандом форест, svm..\n",
    "\n",
    "Получилось ли улучшить качество? Почему?\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Фидбек (бесценно)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "* Какие аспекты обучения  ансамблей Вам показались непонятными? Какое место стоит дополнительно объяснить?"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### Ваш ответ здесь"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Не могли бы вы дать комментарий по поводу неясностей, описанных в ходе решения (в комментариях)?\n",
    "А то обычно за домашку просто проставляются баллы и всё непонятое остается непонятным.\n",
    "\n",
    "Спасибо"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "### ВАШ ОТЗЫВ ЗДЕСЬ\n",
    "\n"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    }
   },
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "anaconda-cloud": {},
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
