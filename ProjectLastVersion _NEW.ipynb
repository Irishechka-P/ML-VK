{
  "nbformat": 4,
  "nbformat_minor": 0,
  "metadata": {
    "colab": {
      "name": "ProjectLastVersion.ipynb",
      "provenance": []
    },
    "kernelspec": {
      "name": "python3",
      "display_name": "Python 3"
    },
    "language_info": {
      "name": "python"
    }
  },
  "cells": [
    {
      "cell_type": "code",
      "execution_count": null,
      "metadata": {
        "id": "2g-X0p_vSnfX"
      },
      "outputs": [],
      "source": [
        "! pip install pyod"
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "import pandas as pd\n",
        "import numpy as np\n",
        "from pyod.models.copod import COPOD\n",
        "from sklearn.metrics import f1_score, pairwise_distances"
      ],
      "metadata": {
        "id": "nDS9bQuWSyYN"
      },
      "execution_count": 62,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "def ngrams(text):\n",
        "  text = text.lower()\n",
        "  text_pairs = []\n",
        "  text_halfs = []\n",
        "  text = text.split()\n",
        "\n",
        "  # добавляем пары слов\n",
        "  for i in range(len(text) - 1):\n",
        "    text_pairs.append(text[i]+text[i+1])\n",
        "  \n",
        "  # добавляем половинки слов\n",
        "  for word in text:\n",
        "    size = len(word) // 2\n",
        "    if size < 2:\n",
        "      continue\n",
        "    text_halfs.append(word[:size])\n",
        "    text_halfs.append(word[size:])\n",
        "\n",
        "  return text, text_halfs, text_pairs\n",
        "\n",
        "\n",
        "def pairwise_similarity(text1, text2):\n",
        "\n",
        "  # 0.67597\n",
        "  w_half = 4\n",
        "  w = 1\n",
        "  w_pair = 4\n",
        "  \n",
        "  text1, text1_halfs, text1_pairs = ngrams(text1)\n",
        "  text2, text2_halfs, text2_pairs = ngrams(text2)\n",
        "\n",
        "  if len(text1) == 0 and len(text1) == 0:\n",
        "    return 0.\n",
        "\n",
        "  initial_intersection =  len(set(text1) & set(text2))\n",
        "  # print(initial_intersection, set(text1), set(text2))\n",
        "  \n",
        "  halfs_intersection = len(set(text1_halfs) & set(text2_halfs))\n",
        "  # print(halfs_intersection, set(text1_halfs), set(text2_halfs))\n",
        "  \n",
        "  pairs_intersection = len(set(text1_pairs) & set(text2_pairs))\n",
        "  # print(pairs_intersection, set(text1_pairs), set(text2_pairs))\n",
        "\n",
        "  return int(200 * (w_half * halfs_intersection + w_pair * pairs_intersection + w * initial_intersection) / (len(text1) + len(text2)))\n"
      ],
      "metadata": {
        "id": "RnzF_cx9Szwr"
      },
      "execution_count": 63,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "doc_to_title = {}\n",
        "with open('docs_titles.tsv') as f:\n",
        "    for num_line, line in enumerate(f):\n",
        "        if num_line == 0:\n",
        "            continue\n",
        "        data = line.strip().split('\\t', 1)\n",
        "        doc_id = int(data[0])\n",
        "        if len(data) == 1:\n",
        "            title = ''\n",
        "        else:\n",
        "            title = data[1]\n",
        "        doc_to_title[doc_id] = title\n",
        "len(doc_to_title)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "LPrHsFefSz8q",
        "outputId": "a8fa6020-3699-4364-b957-2a23f75566b5"
      },
      "execution_count": 64,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "28026"
            ]
          },
          "metadata": {},
          "execution_count": 64
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "train_data = pd.read_csv('train_groups.csv')\n",
        "traingroups_titledata = {}\n",
        "for i in range(len(train_data)):\n",
        "    new_doc = train_data.iloc[i]\n",
        "    doc_group = new_doc['group_id']\n",
        "    doc_id = new_doc['doc_id']\n",
        "    target = new_doc['target']\n",
        "    title = doc_to_title[doc_id]\n",
        "    if doc_group not in traingroups_titledata:\n",
        "        traingroups_titledata[doc_group] = []\n",
        "    traingroups_titledata[doc_group].append((doc_id, title, target))"
      ],
      "metadata": {
        "id": "1d_4wL85S0B-"
      },
      "execution_count": 65,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data = pd.read_csv('test_groups.csv')\n",
        "testgroups_titledata = {}\n",
        "for i in range(len(test_data)):\n",
        "    new_doc = test_data.iloc[i]\n",
        "    doc_group = new_doc['group_id']\n",
        "    doc_id = new_doc['doc_id']\n",
        "    title = doc_to_title[doc_id]\n",
        "    if doc_group not in testgroups_titledata:\n",
        "        testgroups_titledata[doc_group] = []\n",
        "    testgroups_titledata[doc_group].append((doc_id, title))"
      ],
      "metadata": {
        "id": "lxzVYRUXS0FV"
      },
      "execution_count": 66,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "N = 25\n",
        "\n",
        "y_train = []\n",
        "X_train = []\n",
        "\n",
        "for new_group in traingroups_titledata:\n",
        "    docs = traingroups_titledata[new_group]\n",
        "    for k, (doc_id, title, target_id) in enumerate(docs):\n",
        "        # print(title)\n",
        "        y_train.append(target_id)\n",
        "        all_dist = []\n",
        "        # words = set(title.strip().split())\n",
        "        for j in range(0, len(docs)):\n",
        "            if k == j:\n",
        "                continue\n",
        "            doc_id_j, title_j, target_j = docs[j]\n",
        "            # words_j = set(title_j.strip().split())\n",
        "            all_dist.append(pairwise_similarity(title, title_j))\n",
        "            \n",
        "        X_train.append(sorted(all_dist, reverse=True)[0:N])\n",
        "\n",
        "X_train = np.array(X_train)\n",
        "y_train = np.array(y_train)\n",
        "X_train.shape, y_train.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "2sTOqy2_S0I9",
        "outputId": "95cf2edc-30dc-497d-aba6-d0615dbc0048"
      },
      "execution_count": 67,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((11690, 25), (11690,))"
            ]
          },
          "metadata": {},
          "execution_count": 67
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "X_test_id = []\n",
        "X_test = []\n",
        "\n",
        "for new_group in testgroups_titledata:\n",
        "    docs = testgroups_titledata[new_group]\n",
        "    for k, (doc_id, title) in enumerate(docs):\n",
        "        all_dist = []\n",
        "        # words = set(title.strip().split())\n",
        "        for j in range(0, len(docs)):\n",
        "            if k == j:\n",
        "                continue\n",
        "            doc_id_j, title_j = docs[j]\n",
        "            # words_j = set(title_j.strip().split())\n",
        "            all_dist.append(pairwise_similarity(title, title_j))\n",
        "            \n",
        "        X_test.append(sorted(all_dist, reverse=True)[0:N])\n",
        "        X_test_id.append(doc_id)\n",
        "        \n",
        "\n",
        "X_test = np.array(X_test)\n",
        "X_test_id = np.array(X_test_id)\n",
        "print (X_test.shape)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "C6kxGlH7TRyC",
        "outputId": "08faa953-0bd1-4547-9a01-5ad41584105f"
      },
      "execution_count": 68,
      "outputs": [
        {
          "output_type": "stream",
          "name": "stdout",
          "text": [
            "(16627, 25)\n"
          ]
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "cpd = COPOD(contamination=0.3)\n",
        "\n",
        "cpd.fit(X_train)\n",
        "ans_cpd = cpd.predict(X_train)\n",
        "\n",
        "f1_score(ans_cpd, y_train)"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "0t_7--ZJTR1D",
        "outputId": "ac3b856f-c67d-4f05-8d1a-3344105cf518"
      },
      "execution_count": 69,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "0.6736566186107471"
            ]
          },
          "metadata": {},
          "execution_count": 69
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        ""
      ],
      "metadata": {
        "id": "e4-kbaNmDR2Q"
      },
      "execution_count": null,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_ans = cpd.predict(X_test)\n",
        "test_ans.shape, X_test_id.shape"
      ],
      "metadata": {
        "colab": {
          "base_uri": "https://localhost:8080/"
        },
        "id": "6uw2hlEUTR39",
        "outputId": "13831ec9-4a12-4e75-c996-46c677e918aa"
      },
      "execution_count": 70,
      "outputs": [
        {
          "output_type": "execute_result",
          "data": {
            "text/plain": [
              "((16627,), (16627,))"
            ]
          },
          "metadata": {},
          "execution_count": 70
        }
      ]
    },
    {
      "cell_type": "code",
      "source": [
        "d = {}\n",
        "\n",
        "for i in range(16627):\n",
        "  d[X_test_id[i]] = test_ans[i]"
      ],
      "metadata": {
        "id": "MPCLVpElTR65"
      },
      "execution_count": 71,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_target = []\n",
        "\n",
        "for i in range(len(test_data)):\n",
        "    new_doc = test_data.iloc[i]\n",
        "    id = new_doc['doc_id']\n",
        "    test_target.append(d[id])"
      ],
      "metadata": {
        "id": "-0X2lmglTz61"
      },
      "execution_count": 72,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data['target'] = test_target\n",
        "test_data = test_data[['pair_id', 'target']]"
      ],
      "metadata": {
        "id": "7cZeN08WTz99"
      },
      "execution_count": 73,
      "outputs": []
    },
    {
      "cell_type": "code",
      "source": [
        "test_data.to_csv('cpd_new_x4.csv', index=False)"
      ],
      "metadata": {
        "id": "XHRCRJGQT4rp"
      },
      "execution_count": 74,
      "outputs": []
    }
  ]
}